{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f619c15e-05ee-4098-93dd-0b7c8a21cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73573326-30ad-453b-b72c-3edaade07780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size:  torch.Size([2, 6, 4])\n",
      "tensor([[[ 0.8106, -1.8630, -0.3909, -0.8853],\n",
      "         [-1.4399, -0.7427, -2.3332,  1.2521],\n",
      "         [-0.0532, -2.2048, -0.2329,  1.8016],\n",
      "         [ 0.2515,  0.9480, -0.7505,  0.9304],\n",
      "         [-0.8553,  0.1588, -0.2515,  0.5496],\n",
      "         [-0.6063, -1.1989, -1.6598, -1.3802]],\n",
      "\n",
      "        [[ 1.2116,  0.1249,  0.3586,  2.4219],\n",
      "         [ 0.4004,  0.6287,  0.1993,  0.3761],\n",
      "         [-1.6159, -0.1262, -0.1153,  0.4964],\n",
      "         [ 0.5437, -1.8344, -0.5083,  0.9897],\n",
      "         [-1.1565, -0.6082,  1.1919,  2.2440],\n",
      "         [ 0.0358,  0.1542, -0.4149, -0.0404]]])\n",
      "output size:  torch.Size([2, 5, 2])\n",
      "tensor([[[0.4945, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.1120],\n",
      "         [1.3417, 1.3135],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.1645, 0.3309],\n",
      "         [0.4919, 0.0000],\n",
      "         [0.0000, 0.4103],\n",
      "         [0.0000, 0.4062]]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 演示一维卷积： 一维卷积不代表卷积核只有一维，也不代表被卷积的数据也是一维。一维的意思是说卷积的方向是一维的。\n",
    "# 参考解释： https://blog.csdn.net/amateurSU/article/details/138557901\n",
    "\n",
    "batch_size = 2  # 多少批文本数据\n",
    "word_count = 4  # 每批文本包含多少个单词\n",
    "embedding_dim = 6 # 每个单词用多少维向量来表示\n",
    "\n",
    "# 一批数据的张量： 行就是这批文本的各个单词， 列就是每个单词的向量表示\n",
    "#    I Love My Family\n",
    "#    *  *   *   *\n",
    "#    *  *   *   *\n",
    "#    *  *   *   *\n",
    "input_data = torch.randn(batch_size, embedding_dim, word_count)\n",
    "\n",
    "in_channels = embedding_dim  # 每个单词的向量维度\n",
    "\n",
    "# 比如对于如下一批数据， 如果out_channels为5，则会用5个不同的卷积核与这批数据做卷积运算\n",
    "#  [[ 0.2605, -1.5650, -0.5183, -0.4161],\n",
    "#   [ 0.3433,  1.5320,  2.0031,  0.3885],\n",
    "#   [ 2.3063, -0.3679,  0.7549, -0.9822],\n",
    "#   [ 1.5229,  1.4932, -0.4872,  0.7238],\n",
    "#   [ 0.6817,  0.1782, -0.5580, -1.0454],\n",
    "#   [ 1.0688, -1.6322,  0.9375, -0.3195]]\n",
    "\n",
    "# 卷积核的高度是 in_channels，宽度是kernel_size\n",
    "\n",
    "# 根据填充padding为1， 步长stride为2，则：\n",
    "# 第1个卷积核运算结果为：  [0.0839, 0.0000],\n",
    "# 第2个卷积核运算结果为：  [0.3262, 0.2788],\n",
    "# 第3个卷积核运算结果为：  [0.0000, 0.0683],\n",
    "# 第4个卷积核运算结果为：  [0.0000, 0.0000],\n",
    "# 第5个卷积核运算结果为：  [0.6557, 1.5359],\n",
    "\n",
    "# 最后把5个卷积核结果 拼接起来就是 5*2维度的矩阵\n",
    "out_channels = 5  # 卷积的输出通道，也就是有多少个卷积核\n",
    "\n",
    "kernel_size = 3  # 卷积核的大小，此处指宽度， 实际高度是 in_channels, 也就是卷积核其实是二维的\n",
    "\n",
    "stride = 2  # 步幅\n",
    "padding = 1 # 左右填充大小\n",
    "\n",
    "# 沿着句子中各个单词的方向进行卷积运算， 即input_data的第三个维度\n",
    "conv1d_layer = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "relu = nn.ReLU()\n",
    "\n",
    "conv1d_output = conv1d_layer(input_data)\n",
    "output = relu(conv1d_output)  # 应用激活函数\n",
    "\n",
    "# in_channels -> out_channel的变换\n",
    "print('input size: ', input_data.shape)\n",
    "print(input_data)\n",
    "print('output size: ', output.shape) #stride 和 padding参数影响输出的第三个维度\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d95c097-37b3-4bb7-a85f-6727e93faaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 7, 7])\n",
      "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
      "          [ 7.,  8.,  9., 10., 11., 12., 13.],\n",
      "          [14., 15., 16., 17., 18., 19., 20.],\n",
      "          [21., 22., 23., 24., 25., 26., 27.],\n",
      "          [28., 29., 30., 31., 32., 33., 34.],\n",
      "          [35., 36., 37., 38., 39., 40., 41.],\n",
      "          [42., 43., 44., 45., 46., 47., 48.]],\n",
      "\n",
      "         [[49., 50., 51., 52., 53., 54., 55.],\n",
      "          [56., 57., 58., 59., 60., 61., 62.],\n",
      "          [63., 64., 65., 66., 67., 68., 69.],\n",
      "          [70., 71., 72., 73., 74., 75., 76.],\n",
      "          [77., 78., 79., 80., 81., 82., 83.],\n",
      "          [84., 85., 86., 87., 88., 89., 90.],\n",
      "          [91., 92., 93., 94., 95., 96., 97.]]]])\n",
      "\n",
      " torch.Size([1, 1, 5, 5])\n",
      "tensor([[[[22.8329, 23.4452, 24.0576, 24.6699, 25.2823],\n",
      "          [27.1194, 27.7317, 28.3441, 28.9565, 29.5688],\n",
      "          [31.4059, 32.0183, 32.6306, 33.2430, 33.8554],\n",
      "          [35.6924, 36.3048, 36.9172, 37.5295, 38.1419],\n",
      "          [39.9790, 40.5913, 41.2037, 41.8161, 42.4284]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "[Parameter containing:\n",
      "tensor([[[[ 0.1427,  0.2021,  0.0632],\n",
      "          [-0.0887, -0.0483, -0.0234],\n",
      "          [ 0.1980, -0.1099, -0.1496]],\n",
      "\n",
      "         [[-0.0218, -0.1341,  0.2200],\n",
      "          [ 0.2166, -0.0702,  0.0349],\n",
      "          [ 0.1199, -0.0581,  0.1191]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1810], requires_grad=True)]\n",
      "\n",
      " torch.Size([1, 2, 5, 5])\n",
      "tensor([[[[  5.6030,   5.5815,   5.5600,   5.5386,   5.5171],\n",
      "          [  5.4527,   5.4312,   5.4097,   5.3882,   5.3668],\n",
      "          [  5.3023,   5.2809,   5.2594,   5.2379,   5.2165],\n",
      "          [  5.1520,   5.1306,   5.1091,   5.0876,   5.0661],\n",
      "          [  5.0017,   4.9802,   4.9588,   4.9373,   4.9158]],\n",
      "\n",
      "         [[-37.3204, -37.2662, -37.2121, -37.1579, -37.1038],\n",
      "          [-36.9413, -36.8871, -36.8330, -36.7788, -36.7247],\n",
      "          [-36.5622, -36.5081, -36.4539, -36.3998, -36.3456],\n",
      "          [-36.1831, -36.1290, -36.0748, -36.0207, -35.9665],\n",
      "          [-35.8041, -35.7499, -35.6958, -35.6416, -35.5875]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "[Parameter containing:\n",
      "tensor([[[[ 0.1076, -0.0607,  0.0046],\n",
      "          [ 0.1587, -0.1857,  0.1392],\n",
      "          [-0.1153, -0.0958, -0.1117]],\n",
      "\n",
      "         [[-0.0730,  0.1505, -0.1476],\n",
      "          [-0.0262,  0.0349,  0.0622],\n",
      "          [-0.2128,  0.1156,  0.2341]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0472,  0.2028,  0.0135],\n",
      "          [ 0.0316,  0.2101,  0.1205],\n",
      "          [-0.1108,  0.0331,  0.2201]],\n",
      "\n",
      "         [[-0.1527,  0.1548, -0.0791],\n",
      "          [-0.0237, -0.0705, -0.1168],\n",
      "          [-0.2350, -0.2081,  0.0172]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1469, -0.1049], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# 演示二维卷积: in_channels, out_channels, kernel_size\n",
    "in_channels = 2\n",
    "input_data = torch.arange(49 * in_channels,dtype=torch.float32).view(1, in_channels, 7, 7) # 四维数据， 第一维表示批次， 第二维输入通道\n",
    "conv2d_layer = nn.Conv2d(in_channels = in_channels, out_channels = 1, kernel_size = 3)\n",
    "#conv2d_layer = nn.Conv2d(in_channels = in_channels, out_channels = 1, kernel_size = (3, 3))\n",
    "\n",
    "# out_channels = 2表示有2个卷积核，每个卷积核大小 in_channels * kernel_size * kernel_size\n",
    "conv2d_layer2 = nn.Conv2d(in_channels = in_channels, out_channels = 2, kernel_size = 3)\n",
    "\n",
    "output = conv2d_layer(input_data)\n",
    "print(input_data.shape)\n",
    "print(input_data)\n",
    "print('\\n', output.shape)\n",
    "print(output)\n",
    "print(list(conv2d_layer.parameters())) # 卷积核权重\n",
    "\n",
    "output2 = conv2d_layer2(input_data)\n",
    "print('\\n', output2.shape)\n",
    "print(output2)\n",
    "print(list(conv2d_layer2.parameters())) # 卷积核权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68d671da-2649-497e-ba7d-78251546286e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1.,  2.,  3.,  4.],\n",
      "          [ 5.,  6.,  7.,  8.,  9.],\n",
      "          [10., 11., 12., 13., 14.],\n",
      "          [15., 16., 17., 18., 19.],\n",
      "          [20., 21., 22., 23., 24.]]]])\n",
      "tensor([[[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  5.,  6.,  7.,  8.,  9.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0., 10., 11., 12., 13., 14.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0., 15., 16., 17., 18., 19.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0., 20., 21., 22., 23., 24.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "tensor([[[[18., 17., 16., 15., 16., 17., 18., 19., 18., 17., 16.],\n",
      "          [13., 12., 11., 10., 11., 12., 13., 14., 13., 12., 11.],\n",
      "          [ 8.,  7.,  6.,  5.,  6.,  7.,  8.,  9.,  8.,  7.,  6.],\n",
      "          [ 3.,  2.,  1.,  0.,  1.,  2.,  3.,  4.,  3.,  2.,  1.],\n",
      "          [ 8.,  7.,  6.,  5.,  6.,  7.,  8.,  9.,  8.,  7.,  6.],\n",
      "          [13., 12., 11., 10., 11., 12., 13., 14., 13., 12., 11.],\n",
      "          [18., 17., 16., 15., 16., 17., 18., 19., 18., 17., 16.],\n",
      "          [23., 22., 21., 20., 21., 22., 23., 24., 23., 22., 21.],\n",
      "          [18., 17., 16., 15., 16., 17., 18., 19., 18., 17., 16.],\n",
      "          [13., 12., 11., 10., 11., 12., 13., 14., 13., 12., 11.],\n",
      "          [ 8.,  7.,  6.,  5.,  6.,  7.,  8.,  9.,  8.,  7.,  6.]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "tensor([[[[ 0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  4.,  4.,  4.],\n",
      "          [ 0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  4.,  4.,  4.],\n",
      "          [ 0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  4.,  4.,  4.],\n",
      "          [ 0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  4.,  4.,  4.],\n",
      "          [ 5.,  5.,  5.,  5.,  6.,  7.,  8.,  9.,  9.,  9.,  9.],\n",
      "          [10., 10., 10., 10., 11., 12., 13., 14., 14., 14., 14.],\n",
      "          [15., 15., 15., 15., 16., 17., 18., 19., 19., 19., 19.],\n",
      "          [20., 20., 20., 20., 21., 22., 23., 24., 24., 24., 24.],\n",
      "          [20., 20., 20., 20., 21., 22., 23., 24., 24., 24., 24.],\n",
      "          [20., 20., 20., 20., 21., 22., 23., 24., 24., 24., 24.],\n",
      "          [20., 20., 20., 20., 21., 22., 23., 24., 24., 24., 24.]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "tensor([[[[12., 13., 14., 10., 11., 12., 13., 14., 10., 11., 12.],\n",
      "          [17., 18., 19., 15., 16., 17., 18., 19., 15., 16., 17.],\n",
      "          [22., 23., 24., 20., 21., 22., 23., 24., 20., 21., 22.],\n",
      "          [ 2.,  3.,  4.,  0.,  1.,  2.,  3.,  4.,  0.,  1.,  2.],\n",
      "          [ 7.,  8.,  9.,  5.,  6.,  7.,  8.,  9.,  5.,  6.,  7.],\n",
      "          [12., 13., 14., 10., 11., 12., 13., 14., 10., 11., 12.],\n",
      "          [17., 18., 19., 15., 16., 17., 18., 19., 15., 16., 17.],\n",
      "          [22., 23., 24., 20., 21., 22., 23., 24., 20., 21., 22.],\n",
      "          [ 2.,  3.,  4.,  0.,  1.,  2.,  3.,  4.,  0.,  1.,  2.],\n",
      "          [ 7.,  8.,  9.,  5.,  6.,  7.,  8.,  9.,  5.,  6.,  7.],\n",
      "          [12., 13., 14., 10., 11., 12., 13., 14., 10., 11., 12.]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 演示二维卷积: padding, padding_mode\n",
    "img = torch.arange(25, dtype=torch.float32).reshape(1,1,5,5)\n",
    "print(img)\n",
    "\n",
    "# 周围填充0\n",
    "conv_zeros = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1, bias=False, padding=3, padding_mode='zeros')\n",
    "conv_zeros.weight = nn.parameter.Parameter(torch.ones((1,1,1,1)))\n",
    "img_zeros = conv_zeros(img)\n",
    "print(img_zeros)\n",
    "\n",
    "# 以边界对称的点来填充\n",
    "conv_reflect = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1, bias=False, padding=3, padding_mode='reflect')\n",
    "conv_reflect.weight = nn.parameter.Parameter(torch.ones((1,1,1,1)))\n",
    "img_reflect = conv_reflect(img)\n",
    "print(img_reflect)\n",
    "\n",
    "# 复制边界的点填充\n",
    "conv_replicate = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1, bias=False, padding=3, padding_mode='replicate')\n",
    "conv_replicate.weight = nn.parameter.Parameter(torch.ones((1,1,1,1)))\n",
    "img_replicate = conv_replicate(img)\n",
    "print(img_replicate)\n",
    "\n",
    "# 循环复制边界另一侧的点来填充\n",
    "conv_circular = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1, bias=False, padding=3, padding_mode='circular')\n",
    "conv_circular.weight = nn.parameter.Parameter(torch.ones((1,1,1,1)))\n",
    "img_circular = conv_circular(img)\n",
    "print(img_circular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58844dd1-a53b-4496-95dd-04bb1cd898bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "torch.Size([8, 2, 1, 1])\n",
      "tensor([[[[ 3.]],\n",
      "\n",
      "         [[ 7.]],\n",
      "\n",
      "         [[11.]],\n",
      "\n",
      "         [[15.]],\n",
      "\n",
      "         [[19.]],\n",
      "\n",
      "         [[23.]],\n",
      "\n",
      "         [[27.]],\n",
      "\n",
      "         [[31.]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 演示二维卷积: groups\n",
    "# 对输入通道进行分组，节省一半参数量\n",
    "in_channels = 4\n",
    "model = nn.Conv2d(in_channels, out_channels = 8, kernel_size = 1, stride = 1, groups = 2, bias = False)\n",
    "\n",
    "inputs = torch.ones(1, in_channels, 1, 1)\n",
    "print(inputs)\n",
    "\n",
    "# 设置卷积核的权重，也就是对应 out_channels个filter，每个filter对应 in_channels / groups 个卷积核\n",
    "# 1  2\n",
    "# 3  4\n",
    "# 5  6\n",
    "# 7  8\n",
    "# 9  10\n",
    "# 11 12\n",
    "# 12 13\n",
    "# 13 14\n",
    "# 15 16\n",
    "for param in model.parameters():\n",
    "    print(param.size())\n",
    "    param.data = torch.FloatTensor([list(range(1, 17))]).view(8,2,1,1)\n",
    "\n",
    "output = model(inputs)\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
