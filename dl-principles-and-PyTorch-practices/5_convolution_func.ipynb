{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f619c15e-05ee-4098-93dd-0b7c8a21cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73573326-30ad-453b-b72c-3edaade07780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size:  torch.Size([2, 6, 4])\n",
      "tensor([[[ 0.3096,  0.8617,  1.2254, -0.2105],\n",
      "         [-1.8949, -0.1091, -0.7661,  1.4692],\n",
      "         [-0.5503, -1.1103,  1.4052,  0.7749],\n",
      "         [ 0.6824, -0.0054,  0.4503,  0.6455],\n",
      "         [-0.4070,  0.5998,  1.0913,  1.3325],\n",
      "         [-0.5041, -1.5843,  0.1123, -0.2241]],\n",
      "\n",
      "        [[ 0.6990,  0.0096,  1.0308, -0.2351],\n",
      "         [-0.4213,  1.3469,  0.6599, -1.1754],\n",
      "         [ 0.1433, -1.1392,  0.5303,  0.9385],\n",
      "         [ 0.0650,  0.4296,  0.3355,  0.0442],\n",
      "         [ 0.1942, -1.1055,  1.6111, -0.8924],\n",
      "         [-2.3008, -0.4419, -0.4863, -1.1813]]])\n",
      "output size:  torch.Size([2, 5, 2])\n",
      "tensor([[[0.0000, 0.0000],\n",
      "         [0.0416, 0.8747],\n",
      "         [0.0000, 0.8849],\n",
      "         [1.2750, 0.8732],\n",
      "         [0.0595, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0345],\n",
      "         [0.0000, 0.3771],\n",
      "         [0.2332, 0.2971],\n",
      "         [0.8123, 0.7903],\n",
      "         [0.1252, 0.0000]]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 演示一维卷积： 一维卷积不代表卷积核只有一维，也不代表被卷积的数据也是一维。一维的意思是说卷积的方向是一维的。\n",
    "# 参考解释： https://blog.csdn.net/amateurSU/article/details/138557901\n",
    "\n",
    "batch_size = 2  # 多少批文本数据\n",
    "word_count = 4  # 每批文本包含多少个单词\n",
    "embedding_dim = 6 # 每个单词用多少维向量来表示\n",
    "\n",
    "# 一批数据的张量： 行就是这批文本的各个单词， 列就是每个单词的向量表示\n",
    "#    I Love My Family\n",
    "#    *  *   *   *\n",
    "#    *  *   *   *\n",
    "#    *  *   *   *\n",
    "input_data = torch.randn(batch_size, embedding_dim, word_count)\n",
    "\n",
    "in_channels = embedding_dim  # 每个单词的向量维度\n",
    "\n",
    "# 比如对于如下一批数据， 如果out_channels为5，则会用5个不同的卷积核与这批数据做卷积运算\n",
    "#  [[ 0.2605, -1.5650, -0.5183, -0.4161],\n",
    "#   [ 0.3433,  1.5320,  2.0031,  0.3885],\n",
    "#   [ 2.3063, -0.3679,  0.7549, -0.9822],\n",
    "#   [ 1.5229,  1.4932, -0.4872,  0.7238],\n",
    "#   [ 0.6817,  0.1782, -0.5580, -1.0454],\n",
    "#   [ 1.0688, -1.6322,  0.9375, -0.3195]]\n",
    "\n",
    "# 卷积核的高度是 in_channels，宽度是kernel_size\n",
    "\n",
    "# 根据填充padding为1， 步长stride为2，则：\n",
    "# 第1个卷积核运算结果为：  [0.0839, 0.0000],\n",
    "# 第2个卷积核运算结果为：  [0.3262, 0.2788],\n",
    "# 第3个卷积核运算结果为：  [0.0000, 0.0683],\n",
    "# 第4个卷积核运算结果为：  [0.0000, 0.0000],\n",
    "# 第5个卷积核运算结果为：  [0.6557, 1.5359],\n",
    "\n",
    "# 最后把5个卷积核结果 拼接起来就是 5*2维度的矩阵\n",
    "out_channels = 5  # 卷积的输出通道，也就是有多少个卷积核\n",
    "\n",
    "kernel_size = 3  # 卷积核的大小，此处指宽度， 实际高度是 in_channels, 也就是卷积核其实是二维的\n",
    "\n",
    "stride = 2  # 步幅\n",
    "padding = 1 # 左右填充大小\n",
    "\n",
    "# 沿着句子中各个单词的方向进行卷积运算， 即input_data的第三个维度\n",
    "conv1d_layer = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "relu = nn.ReLU()\n",
    "\n",
    "conv1d_output = conv1d_layer(input_data)\n",
    "output = relu(conv1d_output)  # 应用激活函数\n",
    "\n",
    "# in_channels -> out_channel的变换\n",
    "print('input size: ', input_data.shape)\n",
    "print(input_data)\n",
    "print('output size: ', output.shape) #stride 和 padding参数影响输出的第三个维度\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8d95c097-37b3-4bb7-a85f-6727e93faaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 7, 7])\n",
      "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
      "          [ 7.,  8.,  9., 10., 11., 12., 13.],\n",
      "          [14., 15., 16., 17., 18., 19., 20.],\n",
      "          [21., 22., 23., 24., 25., 26., 27.],\n",
      "          [28., 29., 30., 31., 32., 33., 34.],\n",
      "          [35., 36., 37., 38., 39., 40., 41.],\n",
      "          [42., 43., 44., 45., 46., 47., 48.]],\n",
      "\n",
      "         [[49., 50., 51., 52., 53., 54., 55.],\n",
      "          [56., 57., 58., 59., 60., 61., 62.],\n",
      "          [63., 64., 65., 66., 67., 68., 69.],\n",
      "          [70., 71., 72., 73., 74., 75., 76.],\n",
      "          [77., 78., 79., 80., 81., 82., 83.],\n",
      "          [84., 85., 86., 87., 88., 89., 90.],\n",
      "          [91., 92., 93., 94., 95., 96., 97.]]]])\n",
      "\n",
      " torch.Size([1, 1, 5, 5])\n",
      "tensor([[[[-36.8571, -38.3631, -39.8692, -41.3752, -42.8812],\n",
      "          [-47.3993, -48.9054, -50.4114, -51.9174, -53.4235],\n",
      "          [-57.9416, -59.4476, -60.9537, -62.4597, -63.9657],\n",
      "          [-68.4838, -69.9899, -71.4959, -73.0019, -74.5080],\n",
      "          [-79.0261, -80.5321, -82.0382, -83.5442, -85.0502]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "[Parameter containing:\n",
      "tensor([[[[-0.1745,  0.1493, -0.1433],\n",
      "          [-0.2128, -0.1909, -0.1819],\n",
      "          [-0.1752, -0.1536, -0.0605]],\n",
      "\n",
      "         [[ 0.1092,  0.1769, -0.2075],\n",
      "          [ 0.2017,  0.1698, -0.2054],\n",
      "          [-0.1519, -0.2202, -0.2350]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0708], requires_grad=True)]\n",
      "\n",
      " torch.Size([1, 2, 5, 5])\n",
      "tensor([[[[13.1782, 13.4716, 13.7651, 14.0586, 14.3521],\n",
      "          [15.2325, 15.5259, 15.8194, 16.1129, 16.4064],\n",
      "          [17.2868, 17.5802, 17.8737, 18.1672, 18.4606],\n",
      "          [19.3411, 19.6345, 19.9280, 20.2215, 20.5149],\n",
      "          [21.3954, 21.6888, 21.9823, 22.2758, 22.5692]],\n",
      "\n",
      "         [[17.2831, 17.3264, 17.3698, 17.4131, 17.4564],\n",
      "          [17.5865, 17.6298, 17.6732, 17.7165, 17.7599],\n",
      "          [17.8899, 17.9332, 17.9766, 18.0199, 18.0633],\n",
      "          [18.1933, 18.2366, 18.2800, 18.3233, 18.3667],\n",
      "          [18.4967, 18.5401, 18.5834, 18.6267, 18.6701]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "[Parameter containing:\n",
      "tensor([[[[ 0.1889, -0.1524, -0.1257],\n",
      "          [ 0.1026,  0.0945,  0.0987],\n",
      "          [-0.0209,  0.0588, -0.1728]],\n",
      "\n",
      "         [[ 0.0959,  0.0427, -0.1541],\n",
      "          [-0.0552,  0.1262,  0.0978],\n",
      "          [-0.0624,  0.0512,  0.0798]]],\n",
      "\n",
      "\n",
      "        [[[-0.0175, -0.0866,  0.1244],\n",
      "          [ 0.1529,  0.0032, -0.1524],\n",
      "          [-0.0823, -0.1522, -0.1365]],\n",
      "\n",
      "         [[ 0.0881,  0.1802, -0.1382],\n",
      "          [ 0.1529, -0.1857,  0.0834],\n",
      "          [-0.1253,  0.1451,  0.1897]]]], requires_grad=True), Parameter containing:\n",
      "tensor([0.1167, 0.1924], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# 演示二维卷积: in_channels, out_channels, kernel_size\n",
    "in_channels = 2\n",
    "input_data = torch.arange(49 * in_channels,dtype=torch.float32).view(1, in_channels, 7, 7) # 四维数据， 第一维表示批次， 第二维输入通道\n",
    "conv2d_layer = nn.Conv2d(in_channels = in_channels, out_channels = 1, kernel_size = 3)\n",
    "#conv2d_layer = nn.Conv2d(in_channels = in_channels, out_channels = 1, kernel_size = (3, 3))\n",
    "\n",
    "# out_channels = 2表示有2个卷积核，每个卷积核大小 in_channels * kernel_size * kernel_size\n",
    "conv2d_layer2 = nn.Conv2d(in_channels = in_channels, out_channels = 2, kernel_size = 3)\n",
    "\n",
    "\n",
    "output = conv2d_layer(input_data)\n",
    "print(input_data.shape)\n",
    "print(input_data)\n",
    "print('\\n', output.shape)\n",
    "print(output)\n",
    "print(list(conv2d_layer.parameters())) # 卷积核权重\n",
    "\n",
    "output2 = conv2d_layer2(input_data)\n",
    "print('\\n', output2.shape)\n",
    "print(output2)\n",
    "print(list(conv2d_layer2.parameters())) # 卷积核权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "68d671da-2649-497e-ba7d-78251546286e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1.,  2.,  3.,  4.],\n",
      "          [ 5.,  6.,  7.,  8.,  9.],\n",
      "          [10., 11., 12., 13., 14.],\n",
      "          [15., 16., 17., 18., 19.],\n",
      "          [20., 21., 22., 23., 24.]]]])\n",
      "tensor([[[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  5.,  6.,  7.,  8.,  9.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0., 10., 11., 12., 13., 14.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0., 15., 16., 17., 18., 19.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0., 20., 21., 22., 23., 24.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "tensor([[[[18., 17., 16., 15., 16., 17., 18., 19., 18., 17., 16.],\n",
      "          [13., 12., 11., 10., 11., 12., 13., 14., 13., 12., 11.],\n",
      "          [ 8.,  7.,  6.,  5.,  6.,  7.,  8.,  9.,  8.,  7.,  6.],\n",
      "          [ 3.,  2.,  1.,  0.,  1.,  2.,  3.,  4.,  3.,  2.,  1.],\n",
      "          [ 8.,  7.,  6.,  5.,  6.,  7.,  8.,  9.,  8.,  7.,  6.],\n",
      "          [13., 12., 11., 10., 11., 12., 13., 14., 13., 12., 11.],\n",
      "          [18., 17., 16., 15., 16., 17., 18., 19., 18., 17., 16.],\n",
      "          [23., 22., 21., 20., 21., 22., 23., 24., 23., 22., 21.],\n",
      "          [18., 17., 16., 15., 16., 17., 18., 19., 18., 17., 16.],\n",
      "          [13., 12., 11., 10., 11., 12., 13., 14., 13., 12., 11.],\n",
      "          [ 8.,  7.,  6.,  5.,  6.,  7.,  8.,  9.,  8.,  7.,  6.]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "tensor([[[[ 0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  4.,  4.,  4.],\n",
      "          [ 0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  4.,  4.,  4.],\n",
      "          [ 0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  4.,  4.,  4.],\n",
      "          [ 0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  4.,  4.,  4.],\n",
      "          [ 5.,  5.,  5.,  5.,  6.,  7.,  8.,  9.,  9.,  9.,  9.],\n",
      "          [10., 10., 10., 10., 11., 12., 13., 14., 14., 14., 14.],\n",
      "          [15., 15., 15., 15., 16., 17., 18., 19., 19., 19., 19.],\n",
      "          [20., 20., 20., 20., 21., 22., 23., 24., 24., 24., 24.],\n",
      "          [20., 20., 20., 20., 21., 22., 23., 24., 24., 24., 24.],\n",
      "          [20., 20., 20., 20., 21., 22., 23., 24., 24., 24., 24.],\n",
      "          [20., 20., 20., 20., 21., 22., 23., 24., 24., 24., 24.]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "tensor([[[[12., 13., 14., 10., 11., 12., 13., 14., 10., 11., 12.],\n",
      "          [17., 18., 19., 15., 16., 17., 18., 19., 15., 16., 17.],\n",
      "          [22., 23., 24., 20., 21., 22., 23., 24., 20., 21., 22.],\n",
      "          [ 2.,  3.,  4.,  0.,  1.,  2.,  3.,  4.,  0.,  1.,  2.],\n",
      "          [ 7.,  8.,  9.,  5.,  6.,  7.,  8.,  9.,  5.,  6.,  7.],\n",
      "          [12., 13., 14., 10., 11., 12., 13., 14., 10., 11., 12.],\n",
      "          [17., 18., 19., 15., 16., 17., 18., 19., 15., 16., 17.],\n",
      "          [22., 23., 24., 20., 21., 22., 23., 24., 20., 21., 22.],\n",
      "          [ 2.,  3.,  4.,  0.,  1.,  2.,  3.,  4.,  0.,  1.,  2.],\n",
      "          [ 7.,  8.,  9.,  5.,  6.,  7.,  8.,  9.,  5.,  6.,  7.],\n",
      "          [12., 13., 14., 10., 11., 12., 13., 14., 10., 11., 12.]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 演示二维卷积: padding, padding_mode\n",
    "img = torch.arange(25, dtype=torch.float32).reshape(1,1,5,5)\n",
    "print(img)\n",
    "\n",
    "# 周围填充0\n",
    "conv_zeros = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1, bias=False, padding=3, padding_mode='zeros')\n",
    "conv_zeros.weight = nn.parameter.Parameter(torch.ones((1,1,1,1)))\n",
    "img_zeros = conv_zeros(img)\n",
    "print(img_zeros)\n",
    "\n",
    "# 以边界对称的点来填充\n",
    "conv_reflect = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1, bias=False, padding=3, padding_mode='reflect')\n",
    "conv_reflect.weight = nn.parameter.Parameter(torch.ones((1,1,1,1)))\n",
    "img_reflect = conv_reflect(img)\n",
    "print(img_reflect)\n",
    "\n",
    "# 复制边界的点填充\n",
    "conv_replicate = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1, bias=False, padding=3, padding_mode='replicate')\n",
    "conv_replicate.weight = nn.parameter.Parameter(torch.ones((1,1,1,1)))\n",
    "img_replicate = conv_replicate(img)\n",
    "print(img_replicate)\n",
    "\n",
    "# 循环复制边界另一侧的点来填充\n",
    "conv_circular = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1, bias=False, padding=3, padding_mode='circular')\n",
    "conv_circular.weight = nn.parameter.Parameter(torch.ones((1,1,1,1)))\n",
    "img_circular = conv_circular(img)\n",
    "print(img_circular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "58844dd1-a53b-4496-95dd-04bb1cd898bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "torch.Size([8, 2, 1, 1])\n",
      "tensor([[[[ 3.]],\n",
      "\n",
      "         [[ 7.]],\n",
      "\n",
      "         [[11.]],\n",
      "\n",
      "         [[15.]],\n",
      "\n",
      "         [[19.]],\n",
      "\n",
      "         [[23.]],\n",
      "\n",
      "         [[27.]],\n",
      "\n",
      "         [[31.]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 演示二维卷积: groups\n",
    "# 对输入通道进行分组，节省一半参数量\n",
    "in_channels = 4\n",
    "model = nn.Conv2d(in_channels, out_channels = 8, kernel_size = 1, stride = 1, groups = 2, bias = False)\n",
    "\n",
    "inputs = torch.ones(1, in_channels, 1, 1)\n",
    "print(inputs)\n",
    "\n",
    "# 设置卷积核的权重，也就是对应 out_channels个filter，每个filter对应 in_channels / groups 个卷积核\n",
    "# 1  2\n",
    "# 3  4\n",
    "# 5  6\n",
    "# 7  8\n",
    "# 9  10\n",
    "# 11 12\n",
    "# 12 13\n",
    "# 13 14\n",
    "# 15 16\n",
    "for param in model.parameters():\n",
    "    print(param.size())\n",
    "    param.data = torch.FloatTensor([list(range(1, 17))]).view(8,2,1,1)\n",
    "\n",
    "output = model(inputs)\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
